{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. SOME PRELIMINARIES "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Niall O'Neill (100394545) and Karolina Sidlauskaite (100392576)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\niall\\\\OneDrive\\\\Documents\\\\Big Data Masters\\\\Big Data Intelligence\\\\Assignment 3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import some libraries\n",
    "import matplotlib.pyplot as plt \n",
    "# For plotting data\n",
    "import numpy as np              \n",
    "# For Panda dataframes. A dataframe is a matrix-like structure, \n",
    "# similar to R dataframes  \n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The \"wind_pickle\" file contains data in a binary format called \"Pickle\". Pickle data loads faster than text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('wind_pickle.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the attributes in the dataset. Very important, the output attribute (i.e. the value to be predicted, **energy**, is the first attribute). **Steps** represents the hours in advance of the forecast. We will not use this variable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5937, 556)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['energy',\n",
       " 'steps',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'p54.162.1',\n",
       " 'p54.162.2',\n",
       " 'p54.162.3',\n",
       " 'p54.162.4',\n",
       " 'p54.162.5',\n",
       " 'p54.162.6',\n",
       " 'p54.162.7',\n",
       " 'p54.162.8',\n",
       " 'p54.162.9',\n",
       " 'p54.162.10',\n",
       " 'p54.162.11',\n",
       " 'p54.162.12',\n",
       " 'p54.162.13',\n",
       " 'p54.162.14',\n",
       " 'p54.162.15',\n",
       " 'p54.162.16',\n",
       " 'p54.162.17',\n",
       " 'p54.162.18',\n",
       " 'p54.162.19',\n",
       " 'p54.162.20',\n",
       " 'p54.162.21',\n",
       " 'p54.162.22',\n",
       " 'p54.162.23',\n",
       " 'p54.162.24',\n",
       " 'p54.162.25',\n",
       " 'p55.162.1',\n",
       " 'p55.162.2',\n",
       " 'p55.162.3',\n",
       " 'p55.162.4',\n",
       " 'p55.162.5',\n",
       " 'p55.162.6',\n",
       " 'p55.162.7',\n",
       " 'p55.162.8',\n",
       " 'p55.162.9',\n",
       " 'p55.162.10',\n",
       " 'p55.162.11',\n",
       " 'p55.162.12',\n",
       " 'p55.162.13',\n",
       " 'p55.162.14',\n",
       " 'p55.162.15',\n",
       " 'p55.162.16',\n",
       " 'p55.162.17',\n",
       " 'p55.162.18',\n",
       " 'p55.162.19',\n",
       " 'p55.162.20',\n",
       " 'p55.162.21',\n",
       " 'p55.162.22',\n",
       " 'p55.162.23',\n",
       " 'p55.162.24',\n",
       " 'p55.162.25',\n",
       " 'cape.1',\n",
       " 'cape.2',\n",
       " 'cape.3',\n",
       " 'cape.4',\n",
       " 'cape.5',\n",
       " 'cape.6',\n",
       " 'cape.7',\n",
       " 'cape.8',\n",
       " 'cape.9',\n",
       " 'cape.10',\n",
       " 'cape.11',\n",
       " 'cape.12',\n",
       " 'cape.13',\n",
       " 'cape.14',\n",
       " 'cape.15',\n",
       " 'cape.16',\n",
       " 'cape.17',\n",
       " 'cape.18',\n",
       " 'cape.19',\n",
       " 'cape.20',\n",
       " 'cape.21',\n",
       " 'cape.22',\n",
       " 'cape.23',\n",
       " 'cape.24',\n",
       " 'cape.25',\n",
       " 'p59.162.1',\n",
       " 'p59.162.2',\n",
       " 'p59.162.3',\n",
       " 'p59.162.4',\n",
       " 'p59.162.5',\n",
       " 'p59.162.6',\n",
       " 'p59.162.7',\n",
       " 'p59.162.8',\n",
       " 'p59.162.9',\n",
       " 'p59.162.10',\n",
       " 'p59.162.11',\n",
       " 'p59.162.12',\n",
       " 'p59.162.13',\n",
       " 'p59.162.14',\n",
       " 'p59.162.15',\n",
       " 'p59.162.16',\n",
       " 'p59.162.17',\n",
       " 'p59.162.18',\n",
       " 'p59.162.19',\n",
       " 'p59.162.20',\n",
       " 'p59.162.21',\n",
       " 'p59.162.22',\n",
       " 'p59.162.23',\n",
       " 'p59.162.24',\n",
       " 'p59.162.25',\n",
       " 'lai_lv.1',\n",
       " 'lai_lv.2',\n",
       " 'lai_lv.3',\n",
       " 'lai_lv.4',\n",
       " 'lai_lv.5',\n",
       " 'lai_lv.6',\n",
       " 'lai_lv.7',\n",
       " 'lai_lv.8',\n",
       " 'lai_lv.9',\n",
       " 'lai_lv.10',\n",
       " 'lai_lv.11',\n",
       " 'lai_lv.12',\n",
       " 'lai_lv.13',\n",
       " 'lai_lv.14',\n",
       " 'lai_lv.15',\n",
       " 'lai_lv.16',\n",
       " 'lai_lv.17',\n",
       " 'lai_lv.18',\n",
       " 'lai_lv.19',\n",
       " 'lai_lv.20',\n",
       " 'lai_lv.21',\n",
       " 'lai_lv.22',\n",
       " 'lai_lv.23',\n",
       " 'lai_lv.24',\n",
       " 'lai_lv.25',\n",
       " 'lai_hv.1',\n",
       " 'lai_hv.2',\n",
       " 'lai_hv.3',\n",
       " 'lai_hv.4',\n",
       " 'lai_hv.5',\n",
       " 'lai_hv.6',\n",
       " 'lai_hv.7',\n",
       " 'lai_hv.8',\n",
       " 'lai_hv.9',\n",
       " 'lai_hv.10',\n",
       " 'lai_hv.11',\n",
       " 'lai_hv.12',\n",
       " 'lai_hv.13',\n",
       " 'lai_hv.14',\n",
       " 'lai_hv.15',\n",
       " 'lai_hv.16',\n",
       " 'lai_hv.17',\n",
       " 'lai_hv.18',\n",
       " 'lai_hv.19',\n",
       " 'lai_hv.20',\n",
       " 'lai_hv.21',\n",
       " 'lai_hv.22',\n",
       " 'lai_hv.23',\n",
       " 'lai_hv.24',\n",
       " 'lai_hv.25',\n",
       " 'u10n.1',\n",
       " 'u10n.2',\n",
       " 'u10n.3',\n",
       " 'u10n.4',\n",
       " 'u10n.5',\n",
       " 'u10n.6',\n",
       " 'u10n.7',\n",
       " 'u10n.8',\n",
       " 'u10n.9',\n",
       " 'u10n.10',\n",
       " 'u10n.11',\n",
       " 'u10n.12',\n",
       " 'u10n.13',\n",
       " 'u10n.14',\n",
       " 'u10n.15',\n",
       " 'u10n.16',\n",
       " 'u10n.17',\n",
       " 'u10n.18',\n",
       " 'u10n.19',\n",
       " 'u10n.20',\n",
       " 'u10n.21',\n",
       " 'u10n.22',\n",
       " 'u10n.23',\n",
       " 'u10n.24',\n",
       " 'u10n.25',\n",
       " 'v10n.1',\n",
       " 'v10n.2',\n",
       " 'v10n.3',\n",
       " 'v10n.4',\n",
       " 'v10n.5',\n",
       " 'v10n.6',\n",
       " 'v10n.7',\n",
       " 'v10n.8',\n",
       " 'v10n.9',\n",
       " 'v10n.10',\n",
       " 'v10n.11',\n",
       " 'v10n.12',\n",
       " 'v10n.13',\n",
       " 'v10n.14',\n",
       " 'v10n.15',\n",
       " 'v10n.16',\n",
       " 'v10n.17',\n",
       " 'v10n.18',\n",
       " 'v10n.19',\n",
       " 'v10n.20',\n",
       " 'v10n.21',\n",
       " 'v10n.22',\n",
       " 'v10n.23',\n",
       " 'v10n.24',\n",
       " 'v10n.25',\n",
       " 'sp.1',\n",
       " 'sp.2',\n",
       " 'sp.3',\n",
       " 'sp.4',\n",
       " 'sp.5',\n",
       " 'sp.6',\n",
       " 'sp.7',\n",
       " 'sp.8',\n",
       " 'sp.9',\n",
       " 'sp.10',\n",
       " 'sp.11',\n",
       " 'sp.12',\n",
       " 'sp.13',\n",
       " 'sp.14',\n",
       " 'sp.15',\n",
       " 'sp.16',\n",
       " 'sp.17',\n",
       " 'sp.18',\n",
       " 'sp.19',\n",
       " 'sp.20',\n",
       " 'sp.21',\n",
       " 'sp.22',\n",
       " 'sp.23',\n",
       " 'sp.24',\n",
       " 'sp.25',\n",
       " 'stl1.1',\n",
       " 'stl1.2',\n",
       " 'stl1.3',\n",
       " 'stl1.4',\n",
       " 'stl1.5',\n",
       " 'stl1.6',\n",
       " 'stl1.7',\n",
       " 'stl1.8',\n",
       " 'stl1.9',\n",
       " 'stl1.10',\n",
       " 'stl1.11',\n",
       " 'stl1.12',\n",
       " 'stl1.13',\n",
       " 'stl1.14',\n",
       " 'stl1.15',\n",
       " 'stl1.16',\n",
       " 'stl1.17',\n",
       " 'stl1.18',\n",
       " 'stl1.19',\n",
       " 'stl1.20',\n",
       " 'stl1.21',\n",
       " 'stl1.22',\n",
       " 'stl1.23',\n",
       " 'stl1.24',\n",
       " 'stl1.25',\n",
       " 'u10.1',\n",
       " 'u10.2',\n",
       " 'u10.3',\n",
       " 'u10.4',\n",
       " 'u10.5',\n",
       " 'u10.6',\n",
       " 'u10.7',\n",
       " 'u10.8',\n",
       " 'u10.9',\n",
       " 'u10.10',\n",
       " 'u10.11',\n",
       " 'u10.12',\n",
       " 'u10.13',\n",
       " 'u10.14',\n",
       " 'u10.15',\n",
       " 'u10.16',\n",
       " 'u10.17',\n",
       " 'u10.18',\n",
       " 'u10.19',\n",
       " 'u10.20',\n",
       " 'u10.21',\n",
       " 'u10.22',\n",
       " 'u10.23',\n",
       " 'u10.24',\n",
       " 'u10.25',\n",
       " 'v10.1',\n",
       " 'v10.2',\n",
       " 'v10.3',\n",
       " 'v10.4',\n",
       " 'v10.5',\n",
       " 'v10.6',\n",
       " 'v10.7',\n",
       " 'v10.8',\n",
       " 'v10.9',\n",
       " 'v10.10',\n",
       " 'v10.11',\n",
       " 'v10.12',\n",
       " 'v10.13',\n",
       " 'v10.14',\n",
       " 'v10.15',\n",
       " 'v10.16',\n",
       " 'v10.17',\n",
       " 'v10.18',\n",
       " 'v10.19',\n",
       " 'v10.20',\n",
       " 'v10.21',\n",
       " 'v10.22',\n",
       " 'v10.23',\n",
       " 'v10.24',\n",
       " 'v10.25',\n",
       " 't2m.1',\n",
       " 't2m.2',\n",
       " 't2m.3',\n",
       " 't2m.4',\n",
       " 't2m.5',\n",
       " 't2m.6',\n",
       " 't2m.7',\n",
       " 't2m.8',\n",
       " 't2m.9',\n",
       " 't2m.10',\n",
       " 't2m.11',\n",
       " 't2m.12',\n",
       " 't2m.13',\n",
       " 't2m.14',\n",
       " 't2m.15',\n",
       " 't2m.16',\n",
       " 't2m.17',\n",
       " 't2m.18',\n",
       " 't2m.19',\n",
       " 't2m.20',\n",
       " 't2m.21',\n",
       " 't2m.22',\n",
       " 't2m.23',\n",
       " 't2m.24',\n",
       " 't2m.25',\n",
       " 'stl2.1',\n",
       " 'stl2.2',\n",
       " 'stl2.3',\n",
       " 'stl2.4',\n",
       " 'stl2.5',\n",
       " 'stl2.6',\n",
       " 'stl2.7',\n",
       " 'stl2.8',\n",
       " 'stl2.9',\n",
       " 'stl2.10',\n",
       " 'stl2.11',\n",
       " 'stl2.12',\n",
       " 'stl2.13',\n",
       " 'stl2.14',\n",
       " 'stl2.15',\n",
       " 'stl2.16',\n",
       " 'stl2.17',\n",
       " 'stl2.18',\n",
       " 'stl2.19',\n",
       " 'stl2.20',\n",
       " 'stl2.21',\n",
       " 'stl2.22',\n",
       " 'stl2.23',\n",
       " 'stl2.24',\n",
       " 'stl2.25',\n",
       " 'stl3.1',\n",
       " 'stl3.2',\n",
       " 'stl3.3',\n",
       " 'stl3.4',\n",
       " 'stl3.5',\n",
       " 'stl3.6',\n",
       " 'stl3.7',\n",
       " 'stl3.8',\n",
       " 'stl3.9',\n",
       " 'stl3.10',\n",
       " 'stl3.11',\n",
       " 'stl3.12',\n",
       " 'stl3.13',\n",
       " 'stl3.14',\n",
       " 'stl3.15',\n",
       " 'stl3.16',\n",
       " 'stl3.17',\n",
       " 'stl3.18',\n",
       " 'stl3.19',\n",
       " 'stl3.20',\n",
       " 'stl3.21',\n",
       " 'stl3.22',\n",
       " 'stl3.23',\n",
       " 'stl3.24',\n",
       " 'stl3.25',\n",
       " 'iews.1',\n",
       " 'iews.2',\n",
       " 'iews.3',\n",
       " 'iews.4',\n",
       " 'iews.5',\n",
       " 'iews.6',\n",
       " 'iews.7',\n",
       " 'iews.8',\n",
       " 'iews.9',\n",
       " 'iews.10',\n",
       " 'iews.11',\n",
       " 'iews.12',\n",
       " 'iews.13',\n",
       " 'iews.14',\n",
       " 'iews.15',\n",
       " 'iews.16',\n",
       " 'iews.17',\n",
       " 'iews.18',\n",
       " 'iews.19',\n",
       " 'iews.20',\n",
       " 'iews.21',\n",
       " 'iews.22',\n",
       " 'iews.23',\n",
       " 'iews.24',\n",
       " 'iews.25',\n",
       " 'inss.1',\n",
       " 'inss.2',\n",
       " 'inss.3',\n",
       " 'inss.4',\n",
       " 'inss.5',\n",
       " 'inss.6',\n",
       " 'inss.7',\n",
       " 'inss.8',\n",
       " 'inss.9',\n",
       " 'inss.10',\n",
       " 'inss.11',\n",
       " 'inss.12',\n",
       " 'inss.13',\n",
       " 'inss.14',\n",
       " 'inss.15',\n",
       " 'inss.16',\n",
       " 'inss.17',\n",
       " 'inss.18',\n",
       " 'inss.19',\n",
       " 'inss.20',\n",
       " 'inss.21',\n",
       " 'inss.22',\n",
       " 'inss.23',\n",
       " 'inss.24',\n",
       " 'inss.25',\n",
       " 'stl4.1',\n",
       " 'stl4.2',\n",
       " 'stl4.3',\n",
       " 'stl4.4',\n",
       " 'stl4.5',\n",
       " 'stl4.6',\n",
       " 'stl4.7',\n",
       " 'stl4.8',\n",
       " 'stl4.9',\n",
       " 'stl4.10',\n",
       " 'stl4.11',\n",
       " 'stl4.12',\n",
       " 'stl4.13',\n",
       " 'stl4.14',\n",
       " 'stl4.15',\n",
       " 'stl4.16',\n",
       " 'stl4.17',\n",
       " 'stl4.18',\n",
       " 'stl4.19',\n",
       " 'stl4.20',\n",
       " 'stl4.21',\n",
       " 'stl4.22',\n",
       " 'stl4.23',\n",
       " 'stl4.24',\n",
       " 'stl4.25',\n",
       " 'fsr.1',\n",
       " 'fsr.2',\n",
       " 'fsr.3',\n",
       " 'fsr.4',\n",
       " 'fsr.5',\n",
       " 'fsr.6',\n",
       " 'fsr.7',\n",
       " 'fsr.8',\n",
       " 'fsr.9',\n",
       " 'fsr.10',\n",
       " 'fsr.11',\n",
       " 'fsr.12',\n",
       " 'fsr.13',\n",
       " 'fsr.14',\n",
       " 'fsr.15',\n",
       " 'fsr.16',\n",
       " 'fsr.17',\n",
       " 'fsr.18',\n",
       " 'fsr.19',\n",
       " 'fsr.20',\n",
       " 'fsr.21',\n",
       " 'fsr.22',\n",
       " 'fsr.23',\n",
       " 'fsr.24',\n",
       " 'fsr.25',\n",
       " 'flsr.1',\n",
       " 'flsr.2',\n",
       " 'flsr.3',\n",
       " 'flsr.4',\n",
       " 'flsr.5',\n",
       " 'flsr.6',\n",
       " 'flsr.7',\n",
       " 'flsr.8',\n",
       " 'flsr.9',\n",
       " 'flsr.10',\n",
       " 'flsr.11',\n",
       " 'flsr.12',\n",
       " 'flsr.13',\n",
       " 'flsr.14',\n",
       " 'flsr.15',\n",
       " 'flsr.16',\n",
       " 'flsr.17',\n",
       " 'flsr.18',\n",
       " 'flsr.19',\n",
       " 'flsr.20',\n",
       " 'flsr.21',\n",
       " 'flsr.22',\n",
       " 'flsr.23',\n",
       " 'flsr.24',\n",
       " 'flsr.25',\n",
       " 'u100.1',\n",
       " 'u100.2',\n",
       " 'u100.3',\n",
       " 'u100.4',\n",
       " 'u100.5',\n",
       " 'u100.6',\n",
       " 'u100.7',\n",
       " 'u100.8',\n",
       " 'u100.9',\n",
       " 'u100.10',\n",
       " 'u100.11',\n",
       " 'u100.12',\n",
       " 'u100.13',\n",
       " 'u100.14',\n",
       " 'u100.15',\n",
       " 'u100.16',\n",
       " 'u100.17',\n",
       " 'u100.18',\n",
       " 'u100.19',\n",
       " 'u100.20',\n",
       " 'u100.21',\n",
       " 'u100.22',\n",
       " 'u100.23',\n",
       " 'u100.24',\n",
       " 'u100.25',\n",
       " 'v100.1',\n",
       " 'v100.2',\n",
       " 'v100.3',\n",
       " 'v100.4',\n",
       " 'v100.5',\n",
       " 'v100.6',\n",
       " 'v100.7',\n",
       " 'v100.8',\n",
       " 'v100.9',\n",
       " 'v100.10',\n",
       " 'v100.11',\n",
       " 'v100.12',\n",
       " 'v100.13',\n",
       " 'v100.14',\n",
       " 'v100.15',\n",
       " 'v100.16',\n",
       " 'v100.17',\n",
       " 'v100.18',\n",
       " 'v100.19',\n",
       " 'v100.20',\n",
       " 'v100.21',\n",
       " 'v100.22',\n",
       " 'v100.23',\n",
       " 'v100.24',\n",
       " 'v100.25']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset contains 5937 instances and 556 attributes (including \n",
    "# the outcome to be predicted)\n",
    "print(data.shape)\n",
    "data.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below, data is going to be separated in train, validation, and test. Given that the use of Pandas dataframes is quite advanced, I am doing this for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indicesTrain = (np.where(data.year<=2006))[0]\n",
    "indicesVal = (np.where((data.year==2007) | (data.year==2008)))[0]\n",
    "indicesTest = (np.where(data.year>=2009))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beware!, **indicesTrain** does not contain the training data, but the *indices* of the training data. For instance, the following cell means that training data is made of instance number 0, instance number 1, ..., up to instance number 2527. This will be important later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 2525, 2526, 2527], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicesTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to transform **data**, which is a Pandas dataframe, to **ava**, which is a NumPy matrix. The reason is that Scikit-learn uses NumPy matrices, not Panda dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ava = data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, **ava** is going to be decomposed into inputs **X** and outputs **y**. And then, into training, validation, and test. For instance, **Xava** and **yava** contain the input attributes, and the output attribute (**energy**) of the whole dataset. Please, ask yourself why the inputs use \"6:\" and the output use \"0\". **Xtrain** and **ytrain** are the same, but for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xava = ava[:,6:]; yava = ava[:,0]\n",
    "Xtrain = ava[indicesTrain,6:]; ytrain = ava[indicesTrain,0]\n",
    "Xval = ava[indicesVal,6:]; yval = ava[indicesVal,0]\n",
    "Xtest = ava[indicesTest,6:]; ytest = ava[indicesTest,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines function **mae** (Mean Absolute Error), that we will use later to measure the accuracy of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(yval_pred, yval):\n",
    "  val_mae = metrics.mean_absolute_error(yval_pred, yval)\n",
    "  return(val_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell trains KNN with (Xtrain, ytrain) and evaluates it with (Xval, yval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 102 ms\n",
      "MAE for KNN with K=5 is 486.91141493456513\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import neighbors\n",
    "n_neighbors = 5\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors, weights='uniform')\n",
    "np.random.seed(0)\n",
    "%time _ = knn.fit(Xtrain, ytrain)\n",
    "yval_pred = knn.predict(Xval)\n",
    "\n",
    "print(\"MAE for KNN with K=5 is {}\".format(mae(yval_pred, yval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KNeighborsRegressor in sklearn.neighbors:\n",
      "\n",
      "sklearn.neighbors.KNeighborsRegressor = class KNeighborsRegressor(sklearn.neighbors.base.NeighborsBase, sklearn.neighbors.base.KNeighborsMixin, sklearn.neighbors.base.SupervisedFloatMixin, sklearn.base.RegressorMixin)\n",
      " |  sklearn.neighbors.KNeighborsRegressor(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)\n",
      " |  \n",
      " |  Regression based on k-nearest neighbors.\n",
      " |  \n",
      " |  The target is predicted by local interpolation of the targets\n",
      " |  associated of the nearest neighbors in the training set.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_neighbors : int, optional (default = 5)\n",
      " |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
      " |  \n",
      " |  weights : str or callable\n",
      " |      weight function used in prediction.  Possible values:\n",
      " |  \n",
      " |      - 'uniform' : uniform weights.  All points in each neighborhood\n",
      " |        are weighted equally.\n",
      " |      - 'distance' : weight points by the inverse of their distance.\n",
      " |        in this case, closer neighbors of a query point will have a\n",
      " |        greater influence than neighbors which are further away.\n",
      " |      - [callable] : a user-defined function which accepts an\n",
      " |        array of distances, and returns an array of the same shape\n",
      " |        containing the weights.\n",
      " |  \n",
      " |      Uniform weights are used by default.\n",
      " |  \n",
      " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional\n",
      " |      Algorithm used to compute the nearest neighbors:\n",
      " |  \n",
      " |      - 'ball_tree' will use :class:`BallTree`\n",
      " |      - 'kd_tree' will use :class:`KDTree`\n",
      " |      - 'brute' will use a brute-force search.\n",
      " |      - 'auto' will attempt to decide the most appropriate algorithm\n",
      " |        based on the values passed to :meth:`fit` method.\n",
      " |  \n",
      " |      Note: fitting on sparse input will override the setting of\n",
      " |      this parameter, using brute force.\n",
      " |  \n",
      " |  leaf_size : int, optional (default = 30)\n",
      " |      Leaf size passed to BallTree or KDTree.  This can affect the\n",
      " |      speed of the construction and query, as well as the memory\n",
      " |      required to store the tree.  The optimal value depends on the\n",
      " |      nature of the problem.\n",
      " |  \n",
      " |  p : integer, optional (default = 2)\n",
      " |      Power parameter for the Minkowski metric. When p = 1, this is\n",
      " |      equivalent to using manhattan_distance (l1), and euclidean_distance\n",
      " |      (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
      " |  \n",
      " |  metric : string or callable, default 'minkowski'\n",
      " |      the distance metric to use for the tree.  The default metric is\n",
      " |      minkowski, and with p=2 is equivalent to the standard Euclidean\n",
      " |      metric. See the documentation of the DistanceMetric class for a\n",
      " |      list of available metrics.\n",
      " |  \n",
      " |  metric_params : dict, optional (default = None)\n",
      " |      Additional keyword arguments for the metric function.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      The number of parallel jobs to run for neighbors search.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |      Doesn't affect :meth:`fit` method.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> X = [[0], [1], [2], [3]]\n",
      " |  >>> y = [0, 0, 1, 1]\n",
      " |  >>> from sklearn.neighbors import KNeighborsRegressor\n",
      " |  >>> neigh = KNeighborsRegressor(n_neighbors=2)\n",
      " |  >>> neigh.fit(X, y) # doctest: +ELLIPSIS\n",
      " |  KNeighborsRegressor(...)\n",
      " |  >>> print(neigh.predict([[1.5]]))\n",
      " |  [0.5]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  NearestNeighbors\n",
      " |  RadiusNeighborsRegressor\n",
      " |  KNeighborsClassifier\n",
      " |  RadiusNeighborsClassifier\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
      " |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
      " |  \n",
      " |  .. warning::\n",
      " |  \n",
      " |     Regarding the Nearest Neighbors algorithms, if it is found that two\n",
      " |     neighbors, neighbor `k+1` and `k`, have identical distances but\n",
      " |     different labels, the results will depend on the ordering of the\n",
      " |     training data.\n",
      " |  \n",
      " |  https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KNeighborsRegressor\n",
      " |      sklearn.neighbors.base.NeighborsBase\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.neighbors.base.KNeighborsMixin\n",
      " |      sklearn.neighbors.base.SupervisedFloatMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict the target for the provided data\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of int, shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          Target values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.neighbors.base.KNeighborsMixin:\n",
      " |  \n",
      " |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n",
      " |      Finds the K-neighbors of a point.\n",
      " |      Returns indices of and distances to the neighbors of each point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |      \n",
      " |      n_neighbors : int\n",
      " |          Number of neighbors to get (default is the value\n",
      " |          passed to the constructor).\n",
      " |      \n",
      " |      return_distance : boolean, optional. Defaults to True.\n",
      " |          If False, distances will not be returned\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dist : array\n",
      " |          Array representing the lengths to points, only present if\n",
      " |          return_distance=True\n",
      " |      \n",
      " |      ind : array\n",
      " |          Indices of the nearest points in the population matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      In the following example, we construct a NeighborsClassifier\n",
      " |      class from an array representing our data set and ask who's\n",
      " |      the closest point to [1,1,1]\n",
      " |      \n",
      " |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=1)\n",
      " |      >>> neigh.fit(samples) # doctest: +ELLIPSIS\n",
      " |      NearestNeighbors(algorithm='auto', leaf_size=30, ...)\n",
      " |      >>> print(neigh.kneighbors([[1., 1., 1.]])) # doctest: +ELLIPSIS\n",
      " |      (array([[0.5]]), array([[2]]))\n",
      " |      \n",
      " |      As you can see, it returns [[0.5]], and [[2]], which means that the\n",
      " |      element is at distance 0.5 and is the third element of samples\n",
      " |      (indexes start at 0). You can also query for multiple points:\n",
      " |      \n",
      " |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
      " |      >>> neigh.kneighbors(X, return_distance=False) # doctest: +ELLIPSIS\n",
      " |      array([[1],\n",
      " |             [2]]...)\n",
      " |  \n",
      " |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n",
      " |      Computes the (weighted) graph of k-Neighbors for points in X\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |      \n",
      " |      n_neighbors : int\n",
      " |          Number of neighbors for each sample.\n",
      " |          (default is value passed to the constructor).\n",
      " |      \n",
      " |      mode : {'connectivity', 'distance'}, optional\n",
      " |          Type of returned matrix: 'connectivity' will return the\n",
      " |          connectivity matrix with ones and zeros, in 'distance' the\n",
      " |          edges are Euclidean distance between points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : sparse matrix in CSR format, shape = [n_samples, n_samples_fit]\n",
      " |          n_samples_fit is the number of samples in the fitted data\n",
      " |          A[i, j] is assigned the weight of edge that connects i to j.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> X = [[0], [3], [1]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=2)\n",
      " |      >>> neigh.fit(X) # doctest: +ELLIPSIS\n",
      " |      NearestNeighbors(algorithm='auto', leaf_size=30, ...)\n",
      " |      >>> A = neigh.kneighbors_graph(X)\n",
      " |      >>> A.toarray()\n",
      " |      array([[1., 0., 1.],\n",
      " |             [0., 1., 1.],\n",
      " |             [1., 0., 1.]])\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      NearestNeighbors.radius_neighbors_graph\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.neighbors.base.SupervisedFloatMixin:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model using X as training data and y as target values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix, BallTree, KDTree}\n",
      " |          Training data. If array or matrix, shape [n_samples, n_features],\n",
      " |          or [n_samples, n_samples] if metric='precomputed'.\n",
      " |      \n",
      " |      y : {array-like, sparse matrix}\n",
      " |          Target values, array of float values, shape = [n_samples]\n",
      " |           or [n_samples, n_outputs]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix instead, shape = (n_samples,\n",
      " |          n_samples_fitted], where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In case you need help for KNN\n",
    "help('sklearn.neighbors.KNeighborsRegressor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell, does hyper-parameter tuning for parameter K (n_neighbors), from 1 to 4 by 1. Please, notice that with **partitions = [(indicesTrain, indicesVal)]** we are telling **gridSearch** to use the training dataset for training the different models with the different parameters, and the validation dataset for testing. Notice that this is different to other notebooks, where crossvalidation was used for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 3 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.98 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "np.random.seed(0)\n",
    "param_grid = {'n_neighbors': list(range(1,4,1))}\n",
    "\n",
    "partitions = [(indicesTrain, indicesVal)]\n",
    "clf = GridSearchCV(neighbors.KNeighborsRegressor(), \n",
    "                   param_grid,\n",
    "                   scoring='neg_mean_absolute_error',\n",
    "                   cv=partitions , verbose=1)\n",
    "%time _ = clf.fit(Xava,yava)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we show the best K parameter and the MAE of the final model built with the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K: {'n_neighbors': 3} and MAE for best K: 503.71169104439315\n"
     ]
    }
   ],
   "source": [
    "print(\"Best K: {} and MAE for best K: {}\".format(clf.best_params_, -clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. HOW LONG DOES IT TAKE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good idea to have some estimation of how long your machine learning algorithm is going to take. In the next two cells, try to estimate how many seconds KNN (with K=3) does it take, with only **100 instances**. With 6000 instances, it will take approximately 60 times that number. You can use **%time** for timing, as in previous cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.62 ms\n",
      "Wall time: 181 ms\n",
      "517.6227072106749\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = 3\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors, weights='uniform')\n",
    "np.random.seed(0)\n",
    "%time knn = knn.fit(Xtrain[0:100], ytrain[0:100])\n",
    "\n",
    "%time yval_pred = knn.predict(Xval)\n",
    "\n",
    "print(mae(yval_pred, yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, do the same for Decision trees with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 60.3 ms\n",
      "Wall time: 6.35 ms\n",
      "468.92703618167826\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree \n",
    "\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "%time clf = clf.fit(Xtrain[0:100], ytrain[0:100])\n",
    "\n",
    "%time yval_pred_tree = clf.predict(Xval)\n",
    "print(mae(yval_pred_tree, yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MODEL SELECTION AND HYPER-PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a KNN model with default hiper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 141 ms\n",
      "MAE for KNN with default hyper-parameters is 486.91141493456513\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsRegressor()\n",
    "\n",
    "%time knn = knn.fit(Xtrain, ytrain)\n",
    "yval_pred_knn = knn.predict(Xval)\n",
    "\n",
    "print(\"MAE for KNN with default hyper-parameters is {}\".format(mae(yval_pred_knn, yval)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do hyper-parameter tuning for KNN. Can you improve results? Note: I will specially value if you use model based optimization (**skopt**). If not possible, use **Randomized Search** instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51.9 ms\n",
      "MAE for KNN with default hyper-parameters is 486.91141493456513\n",
      "MAE for KNN with tuned hyper-parameters is 469.78749943395366\n",
      "Best K: {'n_neighbors': 17} and MAE for best K: 469.78749943395366\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "np.random.seed(0)\n",
    "param_grid = {'n_neighbors': (1,20)}\n",
    "\n",
    "budget = 20\n",
    "partitions = [(indicesTrain, indicesVal)]\n",
    "\n",
    "knnModel = neighbors.KNeighborsRegressor()\n",
    "clf = BayesSearchCV(knnModel, \n",
    "                   param_grid,\n",
    "                   scoring='neg_mean_absolute_error',\n",
    "                   cv=partitions , n_jobs=1, verbose=1,\n",
    "                   refit=False,\n",
    "                   n_iter=budget)\n",
    "\n",
    "clf.fit(Xava, yava)\n",
    "\n",
    "knnModel.set_params(**clf.best_params_)\n",
    "%time knnModel = knnModel.fit(Xtrain, ytrain)\n",
    "yval_pred_knn_tuned = knnModel.predict(Xval)\n",
    "\n",
    "print(\"MAE for KNN with default hyper-parameters is {}\".format(mae(yval_pred_knn, yval)))\n",
    "print(\"MAE for KNN with tuned hyper-parameters is {}\".format(mae(yval_pred_knn_tuned, yval)))\n",
    "print(\"Best K: {} and MAE for best K: {}\".format(clf.best_params_, -clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree for regression with default hiper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.25 s\n",
      "MAE for a Decision Tree with default hyper-parameters is 373.9128637413395\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeRegressor()\n",
    "\n",
    "%time clf = clf.fit(Xtrain, ytrain)\n",
    "yval_pred_dt = clf.predict(Xval)\n",
    "\n",
    "print(\"MAE for a Decision Tree with default hyper-parameters is {}\".format(mae(yval_pred_dt, yval)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do hyper-parameter tuning for Decision trees. Can you improve results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 589 ms\n",
      "MAE for Decicision Tree regressor with default hyper-parameters is 373.9128637413395\n",
      "MAE for Decicision Tree regressor with tuned hyper-parameters is 313.64033351665563\n",
      "Best parameters: {'max_depth': 6, 'min_samples_split': 20} and MAE for best parameters: 313.8131667681501\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "np.random.seed(0)\n",
    "param_grid = {'max_depth': (2,20),\n",
    "              'min_samples_split': (2,20)}\n",
    "\n",
    "budget = 20\n",
    "partitions = [(indicesTrain, indicesVal)]\n",
    "                                        \n",
    "dtModel = tree.DecisionTreeRegressor()\n",
    "clf = BayesSearchCV(dtModel, \n",
    "                   param_grid,\n",
    "                   scoring='neg_mean_absolute_error',\n",
    "                   cv=partitions, n_jobs=1, verbose=1,\n",
    "                   refit=False, \n",
    "                   n_iter=budget)\n",
    "\n",
    "clf.fit(Xava, yava)\n",
    "\n",
    "dtModel.set_params(**clf.best_params_)\n",
    "%time dtModel = dtModel.fit(Xtrain, ytrain)\n",
    "yval_pred_dt_tuned = dtModel.predict(Xval)\n",
    "\n",
    "print(\"MAE for Decicision Tree regressor with default hyper-parameters is {}\".format(mae(yval_pred_dt, yval)))\n",
    "print(\"MAE for Decicision Tree regressor with tuned hyper-parameters is {}\".format(mae(yval_pred_dt_tuned, yval)))\n",
    "print(\"Best parameters: {} and MAE for best parameters: {}\".format(clf.best_params_, -clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Random Forest (RF) with default parameters. A RF is an ensemble technique based on Decision Trees, but instead of training just a single decision tree, it trains many of them and then computes the average of the outputs. Please, bear in mind that a RF with default parameters involves training 100 trees. You can estimate by hand how long it is going to take, and if it is excessive, you can lower the number of decision trees in the ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.43 s\n",
      "MAE for a Random Forest with default hyper-parameters is 289.78950731331787\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "#help('sklearn.ensemble.RandomForestRegressor')\n",
    "\n",
    "%time rf = rf.fit(Xtrain, ytrain)\n",
    "yval_pred_rf = rf.predict(Xval)\n",
    "\n",
    "print(\"MAE for a Random Forest with default hyper-parameters is {}\".format(mae(yval_pred_rf, yval)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do hyper-parameter tuning for Random Forests. Their main hyper-parameter is **n_estimators**, which is the number of decision trees in the ensemble. Check some values around the default value (like, 50, 100, 150, ...). Please, bear in mind this is going to take time ... In case you want to use other hyper-parameters, please ask the teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.6min finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   36.2s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 30s\n",
      "MAE for Random Forest with default hyper-parameters is 289.78950731331787\n",
      "MAE for Random Forest with tuned hyper-parameters is 276.46768025404157\n",
      "Best parameters: {'n_estimators': 200} and MAE for best parameters: 274.8329385296381\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "np.random.seed(0)\n",
    "param_grid = {'n_estimators' : [50,200]}\n",
    "\n",
    "budget = 20\n",
    "partitions = [(indicesTrain, indicesVal)]\n",
    "\n",
    "rfModel = RandomForestRegressor()\n",
    "rf = BayesSearchCV(rfModel, \n",
    "                   param_grid,\n",
    "                   scoring='neg_mean_absolute_error',\n",
    "                   cv=partitions, n_jobs=1, verbose=1,\n",
    "                   refit=False,\n",
    "                   n_iter=budget)\n",
    "\n",
    "rf.fit(Xava, yava)\n",
    "\n",
    "rfModel.set_params(**rf.best_params_)\n",
    "%time rfModel = rfModel.fit(Xtrain, ytrain)\n",
    "yval_pred_rf_tuned = rfModel.predict(Xval)\n",
    "\n",
    "print(\"MAE for Random Forest with default hyper-parameters is {}\".format(mae(yval_pred_rf, yval)))\n",
    "print(\"MAE for Random Forest with tuned hyper-parameters is {}\".format(mae(yval_pred_rf_tuned, yval)))\n",
    "print(\"Best parameters: {} and MAE for best parameters: {}\".format(rf.best_params_, -rf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Gradient Tree Boosting (GB) with default parameters. A GB is also an ensemble technique based on Decision Trees. In this case, the second decision tree tries to fix the mistakes of the first decision tree. The third decision tree tries to fix the mistakes of the first two decision trees. An so on.\n",
    "\n",
    "Please, bear in mind that a GB with default parameters involves training 100 trees. You can estimate by hand how long it is going to take, and if it is excessive, you can lower the number of decision trees in the ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.2 s\n",
      "MAE for Gradient Boosting with default hyper-parameters is 280.0767333336847\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb = GradientBoostingRegressor()\n",
    "# help('sklearn.ensemble.GradientBoostingRegressor')\n",
    "\n",
    "\n",
    "%time gb = gb.fit(Xtrain, ytrain)\n",
    "yval_pred_gb = gb.predict(Xval)\n",
    "\n",
    "print(\"MAE for Gradient Boosting with default hyper-parameters is {}\".format(mae(yval_pred_gb, yval)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do hyper-parameter tuning for Gradient Boosting. Their main hyper-parameter is **n_estimators**, which is the number of decision trees in the ensemble. Check some values around the default value (like, 50, 100, 150, ...). Please, bear in mind this is going to take time ... In case you want to use other hyper-parameters, please ask the teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.9s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.3s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.7s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.4 s\n",
      "MAE for Gradient Boosting with default hyper-parameters is 280.0767333336847\n",
      "MAE for Gradient Boosting with tuned hyper-parameters is 279.40388523994545\n",
      "Best parameters: {'n_estimators': 131} and MAE for best parameters: 279.1293805869523\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "np.random.seed(0)\n",
    "param_grid = {'n_estimators' : [50,200]}\n",
    "\n",
    "budget = 20\n",
    "partitions = [(indicesTrain, indicesVal)] \n",
    "\n",
    "gbModel = GradientBoostingRegressor()\n",
    "gb = BayesSearchCV(gbModel,\n",
    "                   param_grid,\n",
    "                   scoring='neg_mean_absolute_error',\n",
    "                   cv=partitions, n_jobs=1, verbose=1, \n",
    "                   refit=False,\n",
    "                   n_iter=budget)\n",
    "\n",
    "gb.fit(Xava, yava)\n",
    "\n",
    "gbModel.set_params(**gb.best_params_)\n",
    "%time gbModel = gbModel.fit(Xtrain, ytrain)\n",
    "yval_pred_gb_tuned = gbModel.predict(Xval)\n",
    "\n",
    "print(\"MAE for Gradient Boosting with default hyper-parameters is {}\".format(mae(yval_pred_gb, yval)))\n",
    "print(\"MAE for Gradient Boosting with tuned hyper-parameters is {}\".format(mae(yval_pred_gb_tuned, yval)))\n",
    "print(\"Best parameters: {} and MAE for best parameters: {}\".format(gb.best_params_, -gb.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.3 s\n",
      "MAE for XGBoost with default hyper-parameters is 237.92317624967953\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "%time xgb = xgb.fit(Xava,yava)\n",
    "yval_pred_xgb = xgb.predict(Xval)\n",
    "\n",
    "print(\"MAE for XGBoost with default hyper-parameters is {}\".format(mae(yval_pred_xgb, yval)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   37.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   29.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   14.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   60.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   53.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   25.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   17.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.5s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.5s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.4s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.5s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.4s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.6s finished\n",
      "C:\\Users\\Karolina\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.7 s\n",
      "MAE for XGBoost with default hyper-parameters is 237.92317624967953\n",
      "MAE for XGBoost with tuned hyper-parameters is 277.23924457487647\n",
      "Best parameters: {'max_depth': 4, 'n_estimators': 184} and MAE for best parameters: 277.23924457487647\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor \n",
    "\n",
    "np.random.seed(0)\n",
    "param_grid = {'max_depth': (2,20),\n",
    "              'n_estimators' : [50,200]}\n",
    "\n",
    "budget = 20\n",
    "partitions = [(indicesTrain, indicesVal)]\n",
    "\n",
    "xgbModel = XGBRegressor()\n",
    "bst = BayesSearchCV(xgbModel, \n",
    "                   param_grid,\n",
    "                   scoring='neg_mean_absolute_error',\n",
    "                   cv=partitions, n_jobs=1, verbose=1, \n",
    "                   refit=False,\n",
    "                   n_iter=budget)\n",
    "\n",
    "bst.fit(Xava, yava)\n",
    "\n",
    "xgbModel.set_params(**bst.best_params_)\n",
    "%time xgbModel = xgbModel.fit(Xtrain, ytrain)\n",
    "yval_pred_xgb_tuned = xgbModel.predict(Xval)\n",
    "\n",
    "print(\"MAE for XGBoost with default hyper-parameters is {}\".format(mae(yval_pred_xgb, yval)))\n",
    "print(\"MAE for XGBoost with tuned hyper-parameters is {}\".format(mae(yval_pred_xgb_tuned, yval)))\n",
    "print(\"Best parameters: {} and MAE for best parameters: {}\".format(bst.best_params_, -bst.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should know which model performs best, and what hyper-parameters to use. Please, evaluate that best performing model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing model seems to be the one using XGBoost, hence we can now evaluate the model on the test set by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for final XGBoost model on test set is 290.8745479409073\n"
     ]
    }
   ],
   "source": [
    "best = XGBRegressor()\n",
    "best.set_params(**bst.best_params_)\n",
    "best.fit(Xtrain, ytrain)\n",
    "\n",
    "ytest_pred_best = best.predict(Xtest)\n",
    "\n",
    "print(\"MAE for final XGBoost model on test set is {}\".format(mae(ytest_pred_best, ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ATTRIBUTE SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to answer the following questions: \n",
    "\n",
    "- Are all 550 input attributes actually necessary in order to get a good model? Is it possible to have an accurate model that uses fewer than 550 variables? How many? \n",
    "- Is it enough to use only the attributes for the actual Sotavento location? (13th location in the grid)\n",
    "\n",
    "In order to answer these questions, you should consider the following:\n",
    "\n",
    "1) Go through the \"Attribute Selection\" ipython notebook, and understand the main ideas about **SelectKBest** and **Pipeline**.\n",
    "\n",
    "2) Use **SelectKBest** and **Pipeline** (and whatever else you need) in order to find a subset of attributes that allows to build an accurate Decision Tree model. We are going to use here Decision Trees because they are faster (even if Random Forests or Gradient Boosting performed better in previous sections). Please, note that you cannot just copy/paste from the \"Attribute Selection\" notebook. You will have to think about how to use the main ideas from that notebook, and change whatever needs changing. Use also some of the methods from **mlxtend** (sequential forward/backward selection http://rasbt.github.io/mlxtend/)\n",
    "\n",
    "3) Use the test dataset in order to compare between different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import libraries needed\n",
    "import math\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, chi2, f_classif, f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the RMSE value for the Decision Tree model using all attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529.9076830424718\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeRegressor(random_state=0)\n",
    "clf = clf.fit(Xtrain, ytrain)\n",
    "ytestpred = clf.predict(Xtest)\n",
    "print(math.sqrt(metrics.mean_squared_error(ytest, ytestpred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank all the attributes and sort them by the most useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xt0nNV97vHvb2Y0M9LofrEsS5ZljLgYAsZxwA4kIRgSIDQmaWhC24PD8jluTkibhJ7TkNOzelldpyXrtCHJakPrhqSQRRMuLYFyCIQ6OJAWMLZxwGAbX/BFvkiyLcuy7qPZ54/ZshUs0NgeaTTzPp+1Zr3z7tmSfzsoz+zZ7zvva845RESkcIVyXYCIiEwuBb2ISIFT0IuIFDgFvYhIgVPQi4gUOAW9iEiBU9CLiBQ4Bb2ISIFT0IuIFLhIrgsAqK2tdS0tLbkuQ0Qkr6xfv/6Qc65uon7TIuhbWlpYt25drssQEckrZrY7k35auhERKXAKehGRAqegFxEpcAp6EZECp6AXESlwCnoRkQKnoBcRKXB5HfSb9nXzjae3oNshioi8u7wO+vW7u7h3zQ5+snFfrksREZm28jroP/uB2TRWFnPnw7/ihW2dmtmLiIwjr4M+XhTmJ3dcSU0ixn+5by2fXfUS/UMjuS5LRGRayeugB6gri/HYFz/Indedx9q3j/Dxbz3Pmq0duS5LRGTayPugB5hdXcIfLG3ln//bFUTCxud/8Ap3PLiBg90DuS5NRCTnCiLoR31wXi0//fKH+B8fO49/39zO0r9Zw189tZm2rr5clyYikjMFFfQAsUiYL13TyrNf/QhL5tXwjy/s5LpvPs+zb7bnujQRkZwouKAf1VxTwveWf4AXvnYN82YkuOPBDXzxwfX0DiZzXZqIyJQq2KAf1VhZzPc//wF++4pmfrrpIH/9s625LklEZEpNiztMTbYZZXH+7JMXkXKOH/zHLpIjjr+4+eJclyUiMiUKfkY/1l03XMD7Git46JW9WsIRkcCYMOjN7Hwz2zjmcczMvmJm1Wb2rJlt89sq39/M7Dtmtt3MXjOzhZM/jMyURCN8/YYLGBpJ8fLbh3NdjojIlJgw6J1zW51zC5xzC4D3A33AY8BdwGrnXCuw2u8D3AC0+sdK4N7JKPxM1VfEAegZ0IxeRILhdJdulgI7nHO7gWXA/b79fuBm/3wZ8IBLewmoNLOGrFSbBSEzAHRZHBEJitMN+s8BP/LP651zBwD8doZvbwT2jvmZNt/2a8xspZmtM7N1nZ2dp1nGmTO/TSnpRSQgMg56M4sCnwQemajrOG2npKpzbpVzbpFzblFdXV2mZZw1P6HXjF5EAuN0ZvQ3ABucc6NfMW0fXZLx29EribUBs8f8XBOw/2wLzZYTSzc5rkNEZKqcTtDfysllG4AngOX++XLg8THtt/mzbxYD3aNLPNOJlm5EJCgy+sKUmZUA1wG/N6b5buBhM1sB7AFu8e1PATcC20mfoXN71qrNglBodO0mt3WIiEyVjILeOdcH1Lyj7TDps3De2dcBd2Slukmgg7EiEjSB+mYsjDkYm9syRESmTOCCXufRi0jQBC7otXQjIkETvKDX6ZUiEjABDPr01mlGLyIBEbyg91vlvIgEReCC/uTBWCW9iARD4IJ+dOkmpZwXkYAIYNDrYKyIBEsAgz691dKNiARF8ILeb5XzIhIUgQv6k5cpVtKLSDAELuh1MFZEgiZwQa9r3YhI0AQu6EfpWjciEhSBC3ob7462IiIFLHBBr2/GikjQZBT0ZlZpZo+a2RYz22xmS8ys2syeNbNtflvl+5qZfcfMtpvZa2a2cHKHcHpOXqY4p2WIiEyZTGf03waeds5dAFwKbAbuAlY751qB1X4f4Aag1T9WAvdmteKzpIOxIhI0Ewa9mZUDHwbuA3DODTnnjgLLgPt9t/uBm/3zZcADLu0loNLMGrJe+Rk6eXqlkl5EgiGTGf05QCfwAzN71cy+Z2YJoN45dwDAb2f4/o3A3jE/3+bbpgVd60ZEgiaToI8AC4F7nXOXAb2cXKYZz3jntZySq2a20szWmdm6zs7OjIrNFjO0diMigZFJ0LcBbc65l/3+o6SDv310ScZvO8b0nz3m55uA/e/8pc65Vc65Rc65RXV1dWda/xkxdDBWRIJjwqB3zh0E9prZ+b5pKfAm8ASw3LctBx73z58AbvNn3ywGukeXeKaLkJmudSMigRHJsN/vAw+aWRTYCdxO+k3iYTNbAewBbvF9nwJuBLYDfb7vtGKmGb2IBEdGQe+c2wgsGuelpeP0dcAdZ1nXpDJMS/QiEhiB+2YspGf0WroRkaAIbtAr50UkIAIZ9CEzXetGRAIjkEGv0ytFJEiCGfSmg7EiEhwBDXodjBWR4Ahm0KODsSISHIEM+lBIB2NFJDgCGfQ6GCsiQRLMoNe1bkQkQAIZ9CF9YUpEAiSQQQ+mpRsRCYxABn3IQPeYEpGgCGTQm0EqlesqRESmRjCDHh2MFZHgCGTQ62CsiARJIIPeTAdjRSQ4Mgp6M9tlZq+b2UYzW+fbqs3sWTPb5rdVvt3M7Dtmtt3MXjOzhZM5gDOha92ISJCczoz+o865Bc650VsK3gWsds61Aqv9PsANQKt/rATuzVax2aIbj4hIkJzN0s0y4H7//H7g5jHtD7i0l4BKM2s4i38n69L3jFXSi0gwZBr0DviZma03s5W+rd45dwDAb2f49kZg75ifbfNt00bIdBa9iARHJMN+Vzrn9pvZDOBZM9vyHn1tnLZTctW/YawEaG5uzrCM7NDBWBEJkoxm9M65/X7bATwGXA60jy7J+G2H794GzB7z403A/nF+5yrn3CLn3KK6urozH8EZSK/RK+lFJBgmDHozS5hZ2ehz4GPAJuAJYLnvthx43D9/ArjNn32zGOgeXeKZLnTjEREJkkyWbuqBx8xstP8/O+eeNrNXgIfNbAWwB7jF938KuBHYDvQBt2e96rOkyxSLSJBMGPTOuZ3ApeO0HwaWjtPugDuyUt0k0TdjRSRIgvnNWIyUkl5EAiKYQa8ZvYgESECDXqdXikhwBDPoAX1lSkSCIpBBHwpp6UZEgiOQQa+DsSISJIEMel3rRkSCJJBBjw7GikiABDLo05dAUNKLSDAEMuhD411fU0SkQAUy6NPn0WtGLyLBEMig17VuRCRIAhn0Or1SRIIkkEGPZvQiEiCBDHqdRy8iQRLIoDdMp1eKSGAEMuh1rRsRCZJABr0OxopIkGQc9GYWNrNXzexJvz/XzF42s21m9pCZRX17zO9v96+3TE7pZ860Ri8iAXI6M/ovA5vH7H8DuMc51wp0ASt8+wqgyzl3LnCP7zetmJmWbkQkMDIKejNrAj4BfM/vG3AN8Kjvcj9ws3++zO/jX1/q+08butaNiARJpjP6bwF/BKT8fg1w1DmX9PttQKN/3gjsBfCvd/v+v8bMVprZOjNb19nZeYblnxmdXikiQTJh0JvZTUCHc2792OZxuroMXjvZ4Nwq59wi59yiurq6jIrNFl3rRkSCJJJBnyuBT5rZjUAcKCc9w680s4iftTcB+33/NmA20GZmEaACOJL1ys9Ceukm11WIiEyNCWf0zrmvO+eanHMtwOeAnzvnfgd4DviM77YceNw/f8Lv41//uZtmC+I6GCsiQXI259F/DbjTzLaTXoO/z7ffB9T49juBu86uxOwzQ0s3IhIYmSzdnOCcWwOs8c93ApeP02cAuCULtU0a3XhERIJE34wVESlwwQx6XaZYRAIkkEEfMtN59CISGIEMenQwVkQCJJBBH9JVzUQkQAIZ9IZm9CISHMEMek3oRSRAAhn0IX0zVkQCJJBBr6UbEQmSYAa9ZvQiEiABDfpcVyAiMnWCGfRo6UZEgiOQQa+DsSISJIEMejPoHUzyi7c6SY6kJv4BEZE8Fsignz+rnN6hJMu/v5av/+vruS5HRGRSBTLob1vSwut/9nF++4pmHlnfxr6j/bkuSURk0gQy6AESsQi/ubAJgM37j+W4GhGRyTNh0JtZ3MzWmtmvzOwNM/tz3z7XzF42s21m9pCZRX17zO9v96+3TO4Qztx59aUAbG3vyXElIiKTJ5MZ/SBwjXPuUmABcL2ZLQa+AdzjnGsFuoAVvv8KoMs5dy5wj+83LZXFi2iqKubv1+zgjgc3cLB7INcliYhk3YRB79KO+90i/3DANcCjvv1+4Gb/fJnfx7++1Gz6fkXp7k9fwscvnsmzm9u58+GNuS5HRCTrMro5uJmFgfXAucDfATuAo865pO/SBjT6543AXgDnXNLMuoEa4NA7fudKYCVAc3Pz2Y3iLFzVWstVrbXUlcVY9fxOhpIpopHAHroQkQKUUaI550accwuAJuBy4MLxuvnteLP3U76e5Jxb5Zxb5JxbVFdXl2m9k+aCmWWMpBy7DvfmuhQRkaw6ramrc+4osAZYDFSa2egngiZgv3/eBswG8K9XAEeyUexkOndG+sDsk68doKt3KMfViIhkTyZn3dSZWaV/XgxcC2wGngM+47stBx73z5/w+/jXf+7c9L/gwLy6UurLY3xn9TaW3L2aX247NPEPiYjkgUxm9A3Ac2b2GvAK8Kxz7knga8CdZrad9Br8fb7/fUCNb78TuCv7ZWdfvCjML792DY9+YQnl8SJWvbAz1yWJiGTFhAdjnXOvAZeN076T9Hr9O9sHgFuyUt0UKwqHWNRSzZJ5Nazb1ZXrckREskKnl4xjXl0p+4720z80kutSRETOmoJ+HKMHZj/13f/g3jU7GNYVLkUkjynox/HR82fw5aWtlMUjfOPpLfx47Z5clyQicsYU9OMojob56nXn8cgXPkh9eYx1u7VeLyL5S0E/gUuaKvnZG+30DAznuhQRkTOioJ/Ah1pr6R8e4Xe+9zL3/+cuNuzpIg++FiAickJG17oJstuWtFAai/Anj7/Bnz7xBgDzG8q57/OLaKgoznF1IiITs+kwO120aJFbt25drst4T845Oo8P8tyWDv7iyc2UxiIsmF3JJy5p4BPvayAUmrYX6BSRAmVm651ziybsp6A/fS/vPMzf/2IHWw72cKB7gHPqEtxw8Uxuef9sWmoTuS5PRAJCQT8FhkdSPL5xPz98aTeb9nUTCRn/dPvlLJlXk+vSRCQAFPRT7EB3P7fdt5bdR/pYMLuSBbMrWXxONY2VJTRWFVMa0+EQEckuBX0OdPQMcM+zb7HlYA8b9x5l7P+09eUxPr2wifc3V3FVay3xonDuChWRgpBp0GuamUUzyuL81acvAeDQ8UF2H+5j39F+9h/t59/fbOfvf7ED56A0FmF+Qznnzyzjq9edR3UimuPKRaSQaUY/hYaSKZ5/q5OfbjrI3iN9rNt9BAfc8v4mPjivlgsbymmuLqE4qtm+iExMSzd5YMOeLn744m5+9sZBev2VMmOREDddMoumqmJqS6M0VhWz5Jxahb+InEJLN3lgYXMVC5urGEk5Nh84xtuHevnppgP84q0ODh0/eTvDeFGIq86tpbk6wQdaqmitL2VOTYKisL7YLCIT04x+mhoeSdHVN8S29uP87I2DvLD9EPuP9jMwnL5kcrwoxPyGcmaUxbnp0gaWXlCvWb9IwGRtRm9ms4EHgJlACljlnPu2mVUDDwEtwC7gt5xzXWZmwLeBG4E+4PPOuQ1nOpCgKgqHmFEWZ0ZZnCvPrQVgMDnC5gM97Ow8zuv7unlz/zHW7T7C028cpKK4iI/Nr+cPlrYyu7okx9WLyHQy4YzezBqABufcBjMrA9YDNwOfB4445+42s7uAKufc18zsRuD3SQf9FcC3nXNXvNe/oRn9mRsYHuHFnYf5t437+X+vH2AwmaI0FqGhIs6symIumlXOknk1XDyrgsqSItLvwyJSCCbtYKyZPQ78rX9c7Zw74N8M1jjnzjezf/DPf+T7bx3t926/U0GfHW1dfTy96SBtXf0c6O6nraufrQd7SKbS/43ry2N8qLWOmy5p4CPn1Sn0RfLcpByMNbMW0jcKfxmoHw1vH/YzfLdGYO+YH2vzbe8a9JIdTVUl/NcPnfNrbb2DSV7ZdYQdnb28uOMQqze38+j6NsrjEX538Rx+d/EcqhNRfYFLpIBlHPRmVgr8C/AV59yx95gNjvfCKR8bzGwlsBKgubk50zLkNCViEa4+fwZXnw8rrprLUDLFT17dx79vbue7a3bw3TU7ALh8bjU3XdLA7KoS5tYmmF1dQlhX5BQpCBkt3ZhZEfAk8Ixz7pu+7cSSjJZu8o9zjnW7u3irvYf27gEeWd/Gge6BE6/HIiHm1ZVyXn0prfVlnF9fxofPqyMa0SmdItNFNs+6MeA+YPNoyHtPAMuBu/328THtXzKzH5M+GNv9XiEvuWFmfKClmg+0VAPwlWvP49DxQfZ29bGjs5dt7T281X6ctW8f4Scb9wPpu23df/vluva+SJ7J5Kybq4AXgNdJn14J8L9Ir9M/DDQDe4BbnHNH/BvD3wLXkz698nbn3HtO1zWjn956BoZ54MXd/N9ntrJswSwum13JuTPKmF1dTENFsWb5IjmStRm9c+6XjL/uDrB0nP4OuGPCCiVvlMWL+MJH5rH1YA/PbengcT/DBzCDutIYjVXFzK4qoaU2wdzaEubWljK3JkFFSVEOKxcR0CUQJEPhkPGdWy9L31KxZ5DtncfZ19XPvqP9J7Yb9nTxb6/tP+XyzLdfOZcvfGRe7ooXCTgFvZwWM2NGeZwZ5fFxXx9MjrD3SB87O3vZdbiXZ95o56+f2cpnF82mSpdjFskJLa5KVsUiYc6dUcbHLprJyg/P4y+WXUwy5fjLpzbnujSRwFLQy6SaP6uc/371PB5Z38ZfPbWZ6XARPZGg0dKNTLqvXNvK+l1d/MPzO+kdSnLd/JlcPKucmtJYrksTCQTN6GXSxSJhfrxyMZ+6rJEfrd3L8u+v5dZ/fEmze5EpoqCXKREKGfd8dgHr/vhavry0lbfaj7PlYE+uyxIJBAW9TKmqRJRbFjUB6VspisjkU9DLlKsvj2MGHccGc12KSCAo6GXKFYVD1CSidPQo6EWmgoJecqKuLE7HsYGJO4rIWVPQS07Ul8c0oxeZIgp6yYn6sjhb23t4bmsHxweTuS5HpKAp6CUnfnfxHEqiYW7/wSss+cvVbNrXzUhK59WLTIbTvjn4ZND16IOpf2iE57d18tWHNtI3NAJAIhqmLF5EWTxCeXF6e2I/XkR5cYSy2Mm20liE2dUlNFTEdbNzCZxJuTm4SDYVR8N8/KKZPPbFK/nl9kP0DAxzrD9Jz8AwPQNJegaHOXx8iF2HeukZSHJsYJjhkfEnJkVhoySaDv7qRJRELEwiGqEkFqE0FqYkGiERDZOIpdsS0fCJ/iW+78mfCROL6GbpUjgU9JJz588s4/yZZRP2c84xmEyl3wRG3wwGkuw8dJwD3QP0D41wrH+YI31D9A2OcKB7gL6hJL1DI/QOJk98ashEvCjEBTPLqSgu4tKmCq6bP5P5s8p1w3TJS5ncSvD7wE1Ah3PuYt9WDTwEtAC7gN9yznX52wh+G7iR9G0EP++c2zBREVq6kamQSjn6h0foHUrSO3gy/NP7SfoGTz7v6BlkR+dxjvYNs/nAMUYPH4Qsfe2ea+fXM68uQSIa4ZoLZ1AaS386SMQ0d5Kpk82lm38ifQ/YB8a03QWsds7dbWZ3+f2vATcArf5xBXCv34rkXChkJEbDeOIPECcc6R3iuS0dtHX1k0yl2Hmol6c3HTixjPR//LX2o5EQ72usoCSaXgJqrS+lrixGSTRCcVGYkmiYuN8WR8MUF6W3iWiEeFFIxxhk0mRyz9jnzazlHc3LgKv98/uBNaSDfhnwgL9v7EtmVmlmDc65A9kqWGSqVSei/Ob7m05pT6Uc2zqOs2FPFynn2LSvm92H+zg+mGRfVz/PvHmQTM91iISM0niE6pIoVYkoVSVFxIvCRCMhouEQReEQ0cjJbTRsVJZEmVkepyQapjQeYWZFnGL/MzrGIGOd6efM+tHwds4dMLMZvr0R2DumX5tvU9BLwQmF7D2PLyRHUnT1DTMwPELf0Ah9Q0n6h0foH0rvDwynH8cHRzg+mD4Q3dU3RFffEPuODjA4PMJgMsXwSPoxlEwxPOIYGklNWFt9efqTRCwS8o/RN4AQsaIQ8UiYWFGYWCREfMw2Gkm/kcQjIRKxCMXR9GtR/wYTi5zsW1wUJlaU/p36NDK9ZXtBcbz/2uPOacxsJbASoLm5OctliOReJByiriz7N1dxzjE84jjcO0j7sUEGhtMHoduPDTAwnKJ3KP2JYjCZYjCZfrMYHE7RN5TkSG+KoZEUA/5NZHQ7lJz4zePdhENGRXERn76skf990/wsjlSy5UyDvn10ScbMGoAO394GzB7TrwnYP94vcM6tAlZB+mDsGdYhEjhmRjRiNFQU01BRnJXfmUqlPymceHPwbxi9gyP+k0T6zWD09f7hEQaGU/7TSpLntnTyr6/u448/caFm99PQmQb9E8By4G6/fXxM+5fM7MekD8J2a31eZPoLhYx4KH2wGIpO++frSmP82b+9SUfPIPXl8ewXKGdlwqA3sx+RPvBaa2ZtwJ+SDviHzWwFsAe4xXd/ivSpldtJn155+yTULCLTzIUN5QB8btVL1CSiJ9b6Y5EQ0UiYaDh9bCAaHj1OEE5/aS0W4cOttcypSeR4BIUtk7Nubn2Xl5aO09cBd5xtUSKSXy5rrmL5kjns7x6gdzDJUDLF8cEkg8PpYwJDY44XjC4BjSoKGxfNqqCxsphZlXEaKoqZVVlMY2UxDZVxahJRLQedJX27Q0TOWjQS4s+XXZxx/9Evr+050scPX9rNnsN9bD5wjNVb2hkY/vUDw7FIiFmVxTRUxGmsLGZuXYI51QmuPr9OX1DLkC5qJiLThnOOrr5h9h/tZ9/Rfg4c7Wd/9wD7jvaz/2g/bV39dPr7GHzx6nn80fUX5Lji3NJFzUQk75gZ1Yko1YkoFzdWjNunZ2CYW//xJdbt1s3lM6Xr0YtIXimLF7FoTjVr3z7C9o6eXJeTFxT0IpJ3fnNhE5UlRXzqu//J1oMK+4ko6EUk77yvqYInf/8q4kVhfu+H6+gZGM51SdOagl5E8lJTVQl/fcul7DrcxwvbDuW6nGlNQS8ieWvRnCoA3j7Um+NKpjcFvYjkrUQsQn15TEE/AQW9iOS1lpoEj65v41/Wt53VVTgLmYJeRPLa5y6fzezqYv7wkV/xuVUvMpLK/ZdApxsFvYjktU9d1sTz//OjfPHqeWzYc5Q9R/pyXdK0o6AXkbxnZiy9MH2ju52dx3NczfSjoBeRgnBObSkAOxT0p9C1bkSkIFQlotSWRvnLp7Zw3y/fZk5NgpaaEubUJJhTU0JLTYKGijjlxUUUhYM1x1XQi0jBWHXbIl7ccZhdh3rZfbiPNVs76ehpO6VfIhqmvLiIiuIiGiriXNVax4qr5uag4qmhoBeRgrGwuYqFzVW/1tY7mGTPkT52Heql/dgAxwaSdPcP090/zNG+Id5qP86atzr5jUsamFGgt0FU0ItIQUvEIlzYUH7idofvtL3jONd+8xdc8ze/4H2NFVw0q5zq0iiL5lQztzZBZUn+L/VMStCb2fXAt4Ew8D3n3N2T8e+IiJytc2eU8je3XMqv2o6y9u0jPPjyHvqHR068XhQ2FjZXMdPf4WphcxVViSjn1CaoSkRzWHnmsn6HKTMLA28B1wFtwCvArc65N9/tZ3SHKRGZTrr7h3l552Hajw2w+3Afr+zuoqt3iP1H+0n6L2SZwc0LGln54XMoChuRUIhI2CgKh4iEjEg4RJHfn6xPBLm8w9TlwHbn3E5fyI+BZcC7Br2IyHRSUVzExy6aeUr78cEkb7X30N03zJqtHdz/4m4ee3XfhL8vEjJikRBh/wYQCRmRkBEvCvPV687jNy6dNRnDOPnvT8LvbAT2jtlvA654ZyczWwmsBGhubp6EMkREsqs0FjlxsPfq8+v4jUtn0dkzyHDKkRxJkRxxDKf8diRFMuUYTqboHx5hMJliJOVIpvx2JH2D9KqSyV/+mYygt3HaTlkfcs6tAlZBeulmEuoQEZk0Zsailupcl5GRyVg4agNmj9lvAvZPwr8jIiIZmIygfwVoNbO5ZhYFPgc8MQn/joiIZCDrSzfOuaSZfQl4hvTpld93zr2R7X9HREQyMynn0TvnngKemozfLSIipye/v+4lIiITUtCLiBQ4Bb2ISIFT0IuIFLisX+vmjIow6wR2n+GP1wKHsljOdFPI4yvksUFhj09jmx7mOOfqJuo0LYL+bJjZukwu6pOvCnl8hTw2KOzxaWz5RUs3IiIFTkEvIlLgCiHoV+W6gElWyOMr5LFBYY9PY8sjeb9GLyIi760QZvQiIvIe8jrozex6M9tqZtvN7K5c13O6zOz7ZtZhZpvGtFWb2bNmts1vq3y7mdl3/FhfM7OFuat8YmY228yeM7PNZvaGmX3ZtxfK+OJmttbMfuXH9+e+fa6ZvezH95C/gitmFvP72/3rLbmsPxNmFjazV83sSb9fSGPbZWavm9lGM1vn2wrib3M8eRv0/t60fwfcAMwHbjWz+bmt6rT9E3D9O9ruAlY751qB1X4f0uNs9Y+VwL1TVOOZSgJ/6Jy7EFgM3OH/+xTK+AaBa5xzlwILgOvNbDHwDeAeP74uYIXvvwLocs6dC9zj+013XwY2j9kvpLEBfNQ5t2DMqZSF8rd5KudcXj6AJcAzY/a/Dnw913WdwThagE1j9rcCDf55A7DVP/8H0jdZP6VfPjyAx0nfML7gxgeUABtI3zLzEBDx7Sf+RklftnuJfx7x/SzXtb/HmJpIh901wJOk7xxXEGPzde4Cat/RVnB/m6OPvJ3RM/69aRtzVEs21TvnDgD47Qzfnrfj9R/lLwNepoDG55c2NgIdwLPADuCocy7pu4wdw4nx+de7gZqprfi0fAv4IyDl92sonLFB+vamPzOz9f7+1VBAf5vvNCnXo58iGd2btoDk5XjNrBT4F+ArzrljZuMNI911nLZpPT7n3AiwwMwqgceAC8fr5rd5Mz4zuwnocM6tN7OrR5vH6Zp3YxvjSufcfjObATxrZlveo29bivAhAAABhUlEQVQ+ju/X5POMvlDvTdtuZg0Aftvh2/NuvGZWRDrkH3TO/atvLpjxjXLOHQXWkD4WUWlmoxOosWM4MT7/egVwZGorzdiVwCfNbBfwY9LLN9+iMMYGgHNuv992kH6TvpwC/Nsclc9BX6j3pn0CWO6fLye9tj3afps/A2Ax0D36MXM6svTU/T5gs3Pum2NeKpTx1fmZPGZWDFxL+sDlc8BnfLd3jm903J8Bfu78gu9045z7unOuyTnXQvr/Vz93zv0OBTA2ADNLmFnZ6HPgY8AmCuRvc1y5PkhwlgdUbgTeIr02+se5rucM6v8RcAAYJj1rWEF6bXM1sM1vq31fI32W0Q7gdWBRruufYGxXkf54+xqw0T9uLKDxXQK86se3CfgT334OsBbYDjwCxHx73O9v96+fk+sxZDjOq4EnC2lsfhy/8o83RrOjUP42x3vom7EiIgUun5duREQkAwp6EZECp6AXESlwCnoRkQKnoBcRKXAKehGRAqegFxEpcAp6EZEC9/8BfNYedBA/27sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "# We want to rank all attributes, and the best ones will be selected later\n",
    "selector = SelectKBest(f_regression, k=\"all\")\n",
    "selector.fit(Xtrain, ytrain)\n",
    "sorted_attributes = np.argsort(-selector.scores_)\n",
    "sorted_scores = np.sort(-selector.scores_)\n",
    "for index,element in enumerate(zip(sorted_attributes, sorted_scores)):\n",
    "    #print(element)\n",
    "    if index>10: break\n",
    "        \n",
    "plt.plot(-sorted_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a new train data using sorted attributes and check whether RMSE value changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527.9866276261979\n"
     ]
    }
   ],
   "source": [
    "# Prepare a new train data using sorted attributes from above\n",
    "X_train_new = Xtrain[:, sorted_attributes]\n",
    "X_test_new = Xtest[:, sorted_attributes]\n",
    "\n",
    "clf_sorted = tree.DecisionTreeRegressor(random_state=0)\n",
    "clf_sorted = clf_sorted.fit(X_train_new, ytrain)\n",
    "y_test_pred_sorted = clf_sorted.predict(X_test_new)\n",
    "print(math.sqrt(metrics.mean_squared_error(ytest, y_test_pred_sorted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot, it appears that it should be possible to use 450 attributes to get a similar accuracy. So, checking only the first 450 attributes of the sorted set, we get the RMSE value even lower which means we remove 100 variables from the model we get an even better accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525.8844854312125\n"
     ]
    }
   ],
   "source": [
    "clf_red = tree.DecisionTreeRegressor(random_state=0)\n",
    "clf_red = clf_red.fit(X_train_new[:,:450], ytrain)\n",
    "y_test_pred_red = clf_red.predict(X_test_new[:,:450])\n",
    "print(math.sqrt(metrics.mean_squared_error(ytest, y_test_pred_red)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a new train data using only the attributes from Sotavento location and see how RMSE changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532.9148414962884\n"
     ]
    }
   ],
   "source": [
    "# Prepare a new train data using only the attributes from Sotavento location\n",
    "Xtrain_sotavento = Xtrain[:, list(range(18,550,25))] # start from 18th index, which is attribute 'p54.162.13' for Sotavento\n",
    "Xtest_sotavento = Xtest[:, list(range(18,550,25))]\n",
    "\n",
    "clf_sotavento = tree.DecisionTreeRegressor(random_state=0)\n",
    "clf_sotavento = clf_sotavento.fit(Xtrain_sotavento, ytrain)\n",
    "ytest_pred_sotavento = clf_sotavento.predict(Xtest_sotavento)\n",
    "print(math.sqrt(metrics.mean_squared_error(ytest, ytest_pred_sotavento)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of RMSE is slightly higher using only the attributes from Sotavento location, but this is only using 22 variables instead of 550, which is a massive decrease!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 7150 candidates, totalling 7150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "param_grid = {'feature_selection__k': np.arange(Xtrain.shape[1])+1,\n",
    "              'regression__min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14]}\n",
    "\n",
    "partitions = [(indicesTrain, indicesVal)]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "  ('feature_selection', SelectKBest(f_regression)),\n",
    "  ('regression', tree.DecisionTreeRegressor(random_state=0))\n",
    "])\n",
    "\n",
    "clf_grid = GridSearchCV(pipeline,\n",
    "                        param_grid,\n",
    "                        scoring='neg_mean_squared_error',\n",
    "                        cv=partitions, n_jobs=1, verbose=1, refit=False)\n",
    "\n",
    "%time clf_grid = clf_grid.fit(Xava,yava)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf_grid.best_params_, clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sequential feature selection in mlxtend we've tried it in two different ways (however, neither finished running, hence we're unsure which way would perform better), first, setting only the upper bound for the number of features and include within the pipeline to create the model directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 550 out of 550 | elapsed:    2.1s finished\n",
      "Features: 1/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 549 out of 549 | elapsed:    3.4s finished\n",
      "Features: 2/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 548 out of 548 | elapsed:    4.8s finished\n",
      "Features: 3/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 547 out of 547 | elapsed:    6.0s finished\n",
      "Features: 4/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 546 out of 546 | elapsed:    7.5s finished\n",
      "Features: 5/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 545 out of 545 | elapsed:    8.5s finished\n",
      "Features: 6/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 544 out of 544 | elapsed:    9.6s finished\n",
      "Features: 7/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 543 out of 543 | elapsed:   10.8s finished\n",
      "Features: 8/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 542 out of 542 | elapsed:   11.8s finished\n",
      "Features: 9/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 541 out of 541 | elapsed:   13.3s finished\n",
      "Features: 10/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 540 out of 540 | elapsed:   14.4s finished\n",
      "Features: 11/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 539 out of 539 | elapsed:   16.2s finished\n",
      "Features: 12/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 538 out of 538 | elapsed:   17.5s finished\n",
      "Features: 13/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 537 out of 537 | elapsed:   18.9s finished\n",
      "Features: 14/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 536 out of 536 | elapsed:   19.9s finished\n",
      "Features: 15/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 535 out of 535 | elapsed:   21.5s finished\n",
      "Features: 16/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 534 out of 534 | elapsed:   22.1s finished\n",
      "Features: 17/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 533 out of 533 | elapsed:   23.5s finished\n",
      "Features: 18/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 532 out of 532 | elapsed:   25.1s finished\n",
      "Features: 19/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 531 out of 531 | elapsed:   26.7s finished\n",
      "Features: 20/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 530 out of 530 | elapsed:   27.5s finished\n",
      "Features: 21/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 529 out of 529 | elapsed:   27.8s finished\n",
      "Features: 22/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 528 out of 528 | elapsed:   28.6s finished\n",
      "Features: 23/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 527 out of 527 | elapsed:   30.7s finished\n",
      "Features: 24/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 526 out of 526 | elapsed:   31.4s finished\n",
      "Features: 25/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 525 out of 525 | elapsed:   32.1s finished\n",
      "Features: 26/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 524 out of 524 | elapsed:   32.8s finished\n",
      "Features: 27/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 523 out of 523 | elapsed:   34.6s finished\n",
      "Features: 28/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 522 out of 522 | elapsed:   37.5s finished\n",
      "Features: 29/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 521 out of 521 | elapsed:   39.2s finished\n",
      "Features: 30/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "\n",
    "dtr = tree.DecisionTreeRegressor(random_state=0)\n",
    "partitions = [(indicesTrain, indicesVal)]\n",
    "\n",
    "sfs = SFS(dtr,\n",
    "          k_features=265,\n",
    "          forward=True,\n",
    "          floating=False,\n",
    "          scoring='neg_mean_squared_error',\n",
    "          verbose=1,\n",
    "          cv=partitions)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "  ('sfs', sfs),\n",
    "  ('regression', dtr)\n",
    "])\n",
    "\n",
    "param_grid = {'sfs__k_features': [265],\n",
    "              }\n",
    "\n",
    "\n",
    "gs=GridSearchCV(estimator=pipeline,\n",
    "                param_grid=param_grid,\n",
    "                scoring='neg_mean_squared_error',\n",
    "                cv=5,\n",
    "                n_jobs=1,\n",
    "                verbose=1,\n",
    "                refit=False)\n",
    "\n",
    "gs.fit(Xava, yava)\n",
    "\n",
    "dtr.set_params(**gs.best_params_)\n",
    "%time _ = dtr.fit(Xtrain, ytrain)\n",
    "yval_pred = dtr.predict(Xval)\n",
    "\n",
    "print(\"MAE for xgboost regressor with tuned hyper-parameters is {}\".format(mae(yval_pred, yval)))\n",
    "print(\"Best parameters: {} and MAE for best parameters: {}\".format(gs.best_params_, -gs.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we set both lower and upper bounds and plotting the features depending on the standard error. Then, if this has finished running, we would take the indices of the best attributes, and creating new training and testing sets, we would evaluate this new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 550 out of 550 | elapsed:    4.4s finished\n",
      "Features: 1/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 549 out of 549 | elapsed:    6.6s finished\n",
      "Features: 2/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 548 out of 548 | elapsed:    9.1s finished\n",
      "Features: 3/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 547 out of 547 | elapsed:   12.1s finished\n",
      "Features: 4/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 546 out of 546 | elapsed:   15.2s finished\n",
      "Features: 5/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 545 out of 545 | elapsed:   17.6s finished\n",
      "Features: 6/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 544 out of 544 | elapsed:   19.2s finished\n",
      "Features: 7/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 543 out of 543 | elapsed:   21.2s finished\n",
      "Features: 8/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 542 out of 542 | elapsed:   23.6s finished\n",
      "Features: 9/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 541 out of 541 | elapsed:   25.8s finished\n",
      "Features: 10/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 540 out of 540 | elapsed:   28.2s finished\n",
      "Features: 11/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 539 out of 539 | elapsed:   30.2s finished\n",
      "Features: 12/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 538 out of 538 | elapsed:   32.8s finished\n",
      "Features: 13/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 537 out of 537 | elapsed:   35.1s finished\n",
      "Features: 14/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 536 out of 536 | elapsed:   37.0s finished\n",
      "Features: 15/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 535 out of 535 | elapsed:   39.3s finished\n",
      "Features: 16/265[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "sfs = SFS(clf, \n",
    "          k_features=(20,265),\n",
    "          scoring='neg_mean_squared_error',\n",
    "          verbose=1,\n",
    "          cv=3)\n",
    "\n",
    "sfs.fit(Xtrain, ytrain)\n",
    "\n",
    "sfs = sfs.fit(Xtrain, ytrain)\n",
    "fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, it appears that using 265 attributes has given the best results (which is more than half the total number of variables), i.e. the lowest Mean Absolute Error, however, we've discovered that only using the 22 variables for the Sotavento location gives only a slightly worse result, however, this means only having to use 4% of the total number of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
